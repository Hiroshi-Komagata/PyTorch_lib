{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"lZiUt1IhzoEY"},"source":["# 共通処理"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# ReadMe\n","README = 'Common Library for PyTorch\\nAuthor: H. Hiroshi\\nVer:1.0.1'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PQRZKlZUnV0z"},"source":["## ライブラリ"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15537,"status":"ok","timestamp":1681271095681,"user":{"displayName":"駒形寛","userId":"15699501133067429275"},"user_tz":-540},"id":"lxZNigFwkFAM","outputId":"ad294430-f9a2-4cc5-ccb7-529da84d9606"},"outputs":[{"name":"stdout","output_type":"stream","text":["Active code page: 65001\n","Requirement already satisfied: japanize_matplotlib in c:\\users\\peper\\anaconda3\\lib\\site-packages (1.1.3)\n","Requirement already satisfied: matplotlib in c:\\users\\peper\\anaconda3\\lib\\site-packages (from japanize_matplotlib) (3.3.4)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\peper\\anaconda3\\lib\\site-packages (from matplotlib->japanize_matplotlib) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\peper\\anaconda3\\lib\\site-packages (from matplotlib->japanize_matplotlib) (1.3.1)\n","Requirement already satisfied: numpy>=1.15 in c:\\users\\peper\\anaconda3\\lib\\site-packages (from matplotlib->japanize_matplotlib) (1.22.4)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\peper\\anaconda3\\lib\\site-packages (from matplotlib->japanize_matplotlib) (8.2.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\peper\\anaconda3\\lib\\site-packages (from matplotlib->japanize_matplotlib) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\peper\\anaconda3\\lib\\site-packages (from matplotlib->japanize_matplotlib) (2.8.1)\n","Requirement already satisfied: six in c:\\users\\peper\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->japanize_matplotlib) (1.15.0)\n","Requirement already satisfied: torchviz in c:\\users\\peper\\anaconda3\\lib\\site-packages (0.0.2)\n","Requirement already satisfied: torch in c:\\users\\peper\\anaconda3\\lib\\site-packages (from torchviz) (2.0.0+cu118)\n","Requirement already satisfied: graphviz in c:\\users\\peper\\anaconda3\\lib\\site-packages (from torchviz) (0.20.1)\n","Requirement already satisfied: filelock in c:\\users\\peper\\anaconda3\\lib\\site-packages (from torch->torchviz) (3.0.12)\n","Requirement already satisfied: typing-extensions in c:\\users\\peper\\anaconda3\\lib\\site-packages (from torch->torchviz) (3.7.4.3)\n","Requirement already satisfied: sympy in c:\\users\\peper\\anaconda3\\lib\\site-packages (from torch->torchviz) (1.8)\n","Requirement already satisfied: networkx in c:\\users\\peper\\anaconda3\\lib\\site-packages (from torch->torchviz) (2.5)\n","Requirement already satisfied: jinja2 in c:\\users\\peper\\anaconda3\\lib\\site-packages (from torch->torchviz) (2.11.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\peper\\anaconda3\\lib\\site-packages (from jinja2->torch->torchviz) (1.1.1)\n","Requirement already satisfied: decorator>=4.3.0 in c:\\users\\peper\\anaconda3\\lib\\site-packages (from networkx->torch->torchviz) (5.0.6)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\peper\\anaconda3\\lib\\site-packages (from sympy->torch->torchviz) (1.2.1)\n","Requirement already satisfied: torchinfo in c:\\users\\peper\\anaconda3\\lib\\site-packages (1.7.2)\n"]}],"source":["# 必要ライブラリの導入\n","\n","!chcp 65001\n","!pip install japanize_matplotlib\n","!pip install torchviz\n","!pip install torchinfo"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"QbC2YKdWSkFl"},"outputs":[],"source":["# 必要ライブラリのインポート\n","\n","%matplotlib inline\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import japanize_matplotlib\n","from IPython.display import display"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"aOaOdhPtjpm3"},"outputs":[],"source":["# torch関連ライブラリのインポート\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchinfo import summary\n","from torchviz import make_dot\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Qd1-xBouyLbz"},"source":["## 損失計算"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"iid_gnVNySHI"},"outputs":[],"source":["# 損失計算用\n","def eval_loss(loader, device, net, criterion):\n","    \"\"\"\n","    損失率を計算する。\n","    \n","    Parameters\n","    ----------\n","    loade  : データローダー\n","    device  : 処理デバイス\n","    net  : 学習対象のモデルインスタンス\n","    criterion  : 損失関数のインスタンス\n","\n","    Returns\n","    -------\n","    loss : 損失計算結果\n","    \"\"\"\n","\n","    # データローダーから最初の1セットを取得する\n","    for images, labels in loader:\n","        break\n","\n","    # デバイスの割り当て\n","    inputs = images.to(device)\n","    labels = labels.to(device)\n","\n","    # 予測計算\n","    outputs = net(inputs)\n","\n","    #  損失計算\n","    loss = criterion(outputs, labels)\n","\n","    return loss"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## モデルを保存する"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import datetime\n","import os\n","\n","def SaveModel(model, save_path, file_name_pram=None):\n","    now = datetime.datetime.now()\n","    # 学習済みの重みパラメータを保存する\n","    if file_name_pram is not None:\n","        save_path = os.path.join(save_path, now.strftime(\"%Y%m%d%H%M%S\")  + '_' + file_name_pram + '.pth')\n","    else:\n","        save_path = os.path.join(save_path, now.strftime(\"%Y%m%d%H%M%S\") + '.pth')\n","    torch.save(model, save_path)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"o_Rh-IyenBdN"},"source":["## 学習処理"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"2oxPaN69nSz9"},"outputs":[],"source":["# 学習用関数\n","def fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history, scheduler = None, save_better_only=False, save_path=None):\n","    \"\"\"\n","    学習処理を実施する。\n","    \n","    Parameters\n","    ----------\n","    net  : 学習対象のモデルインスタンス\n","    optimizer  : 最適化関数のインスタンス\n","    criterion  : 損失関数のインスタンス\n","    num_epochs   : 繰り返し数\n","    train_loader  : 訓練用のデータローダー\n","    test_loader  : 検証用のデータローダー\n","    device  : 処理デバイス\n","    history  : 学習結果（繰り返し数、訓練損失、訓練精度、検証損失、検証精度）\n","    scheduler  : スケジューラー\n","    save_better_only  : Trueの場合、損失率が最小の場合、保存する\n","    save_path  : モデルを保存するパス\n","\n","    Returns\n","    -------\n","    history  : 学習結果（繰り返し数、訓練損失、訓練精度、検証損失、検証精度）\n","    \"\"\"\n","\n","    # tqdmライブラリのインポート\n","    from tqdm.notebook import tqdm\n","\n","    base_epochs = len(history)\n","  \n","    for epoch in range(base_epochs, num_epochs+base_epochs):\n","        # 1エポックあたりの正解数(精度計算用)\n","        n_train_acc, n_val_acc = 0, 0\n","        # 1エポックあたりの累積損失(平均化前)\n","        train_loss, val_loss = 0, 0\n","        # 1エポックあたりのデータ累積件数\n","        n_train, n_test = 0, 0\n","\n","        #訓練フェーズ\n","        net.train()\n","\n","        for inputs, labels in tqdm(train_loader):\n","            # 1バッチあたりのデータ件数\n","            train_batch_size = len(labels)\n","            # 1エポックあたりのデータ累積件数\n","            n_train += train_batch_size\n","    \n","            # デバイスの割り当て\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # 勾配の初期化\n","            optimizer.zero_grad()\n","\n","            # 予測計算\n","            outputs = net(inputs)\n","\n","            # 損失計算\n","            loss = criterion(outputs, labels)\n","\n","            # 勾配計算\n","            loss.backward()\n","\n","            # パラメータ修正\n","            optimizer.step()\n","\n","            # 予測ラベル導出\n","            predicted = torch.max(outputs, 1)[1]\n","\n","            # 平均前の損失と正解数の計算\n","            # lossは平均計算が行われているので平均前の損失に戻して加算\n","            train_loss += loss.item() * train_batch_size \n","            n_train_acc += (predicted == labels).sum().item() \n","\n","        #予測フェーズ\n","        net.eval()\n","\n","        for inputs_test, labels_test in test_loader:\n","            # 1バッチあたりのデータ件数\n","            test_batch_size = len(labels_test)\n","            # 1エポックあたりのデータ累積件数\n","            n_test += test_batch_size\n","\n","            # デバイスの割り当て\n","            inputs_test = inputs_test.to(device)\n","            labels_test = labels_test.to(device)\n","\n","            # 予測計算\n","            outputs_test = net(inputs_test)\n","\n","            # 損失計算\n","            loss_test = criterion(outputs_test, labels_test)\n"," \n","            # 予測ラベル導出\n","            predicted_test = torch.max(outputs_test, 1)[1]\n","\n","            #  平均前の損失と正解数の計算\n","            # lossは平均計算が行われているので平均前の損失に戻して加算\n","            val_loss +=  loss_test.item() * test_batch_size\n","            n_val_acc +=  (predicted_test == labels_test).sum().item()\n","\n","        if scheduler != None:\n","            # スケジューラを更新する\n","            scheduler.step()\n","        \n","        # 精度計算\n","        train_acc = n_train_acc / n_train\n","        val_acc = n_val_acc / n_test\n","        # 損失計算\n","        avg_train_loss = train_loss / n_train\n","        avg_val_loss = val_loss / n_test\n","        # 結果表示\n","        print (f'Epoch [{(epoch+1)}/{num_epochs+base_epochs}], loss: {avg_train_loss:.5f} acc: {train_acc:.5f} val_loss: {avg_val_loss:.5f}, val_acc: {val_acc:.5f}')\n","        # 記録\n","        item = np.array([epoch+1, avg_train_loss, train_acc, avg_val_loss, val_acc])\n","\n","        # モデルを保存する\n","        if save_path is not None:\n","            if save_better_only and epoch > 1 and history[:, 3].min() < avg_val_loss:\n","                pass\n","            else:\n","                SaveModel(net, save_path, 'epoch{}_valloss{:.5f}_valacc{:.5f}'.format(epoch+1, avg_val_loss, val_acc))\n","\n","        history = np.vstack((history, item))\n","\n","    return history"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4y-xDtK-1k2r"},"source":["##  学習ログ解析用"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"deUA-pP01nla"},"outputs":[],"source":["# 学習ログ解析\n","\n","def evaluate_history(history):\n","    \"\"\"\n","    学習曲線を表示する。\n","    \n","    Parameters\n","    ----------\n","    history  : 学習結果（繰り返し数、訓練損失、訓練精度、検証損失、検証精度）\n","    \"\"\"\n","\n","    #損失と精度の確認\n","    print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}') \n","    print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )\n","\n","    num_epochs = len(history)\n","    unit = num_epochs / 10\n","\n","    # 学習曲線の表示 (損失)\n","    plt.figure(figsize=(9,8))\n","    plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n","    plt.plot(history[:,0], history[:,3], 'k', label='検証')\n","    plt.xticks(np.arange(0,num_epochs+1, unit))\n","    plt.xlabel('繰り返し回数')\n","    plt.ylabel('損失')\n","    plt.title('学習曲線(損失)')\n","    plt.legend()\n","    plt.show()\n","\n","    # 学習曲線の表示 (精度)\n","    plt.figure(figsize=(9,8))\n","    plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n","    plt.plot(history[:,0], history[:,4], 'k', label='検証')\n","    plt.xticks(np.arange(0,num_epochs+1,unit))\n","    plt.xlabel('繰り返し回数')\n","    plt.ylabel('精度')\n","    plt.title('学習曲線(精度)')\n","    plt.legend()\n","    plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4XER2Opbn7q9"},"source":["## イメージとラベルの表示"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"DbrWNFkxoLM8"},"outputs":[],"source":["# イメージとラベル表示\n","def show_images_labels(loader, classes, net, device):\n","    \"\"\"\n","    学習処理を実施する。\n","    \n","    Parameters\n","    ----------\n","    loader  : 検証用データローダー\n","    classes  : 正解データに対応するラベル値のリスト\n","    net  : 学習対象のモデルインスタンス, Noneの場合、正解データのみ表示する\n","    device  : 処理デバイス\n","\n","    \"\"\"\n","\n","    # データローダーから最初の1セットを取得する\n","    for images, labels in loader:\n","        break\n","    # 表示数は50個とバッチサイズのうち小さい方\n","    n_size = min(len(images), 50)\n","\n","    if net is not None:\n","      # デバイスの割り当て\n","      inputs = images.to(device)\n","      labels = labels.to(device)\n","\n","      # 予測計算\n","      outputs = net(inputs)\n","      predicted = torch.max(outputs,1)[1]\n","\n","    # 最初のn_size個の表示\n","    plt.figure(figsize=(20, 15))\n","    for i in range(n_size):\n","        ax = plt.subplot(5, 10, i + 1)\n","        label_name = classes[labels[i]]\n","        # netがNoneでない場合は、予測結果もタイトルに表示する\n","        if net is not None:\n","          predicted_name = classes[predicted[i]]\n","          # 正解かどうかで色分けをする\n","          if label_name == predicted_name:\n","            c = 'k'\n","          else:\n","            c = 'b'\n","          ax.set_title(label_name + ':' + predicted_name, c=c, fontsize=20)\n","        # netがNoneの場合は、正解ラベルのみ表示\n","        else:\n","          ax.set_title(label_name, fontsize=20)\n","        # TensorをNumPyに変換\n","        image_np = images[i].numpy().copy()\n","        # 軸の順番変更 (channel, row, column) -> (row, column, channel)\n","        img = np.transpose(image_np, (1, 2, 0))\n","        # 値の範囲を[-1, 1] -> [0, 1]に戻す\n","        img = (img + 1)/2\n","        # 結果表示\n","        plt.imshow(img)\n","        ax.set_axis_off()\n","    plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-Fm4ambdqLfj"},"source":["## 乱数初期化"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"S1sd3thrqOsw"},"outputs":[],"source":["def torch_seed(seed=123):\n","    \"\"\"\n","    PyTorch乱数固定用\n","    \"\"\"\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.use_deterministic_algorithms = True"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## モデルを使用して画像を分類する"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def ImageRec(model, input_image, classes, device):\n","    \"\"\"\n","    モデルを使用して画像を分類する。\n","    \n","    Parameters\n","    ----------\n","    model  : モデルインスタンス\n","    input_image  : 判定画像\n","    classes  : 分類\n","    device  : 処理デバイス\n","    \"\"\"\n","\n","    # 前処理の定義\n","    preprocess = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor()\n","    ])\n","\n","    # 前処理を行う\n","    input_tensor = preprocess(input_image)\n","    input_tensor = input_tensor.unsqueeze(0)\n","    model = model.to(device)\n","    input_tensor = input_tensor.to(device)\n","    input_tensor_normalize = transforms.Normalize(0.5, 0.5)(input_tensor)\n","\n","    # 推論を行う\n","    model.eval()\n","    with torch.no_grad():\n","        output = model(input_tensor_normalize)\n","\n","    # クラス分類結果を取得\n","    predicted = F.softmax(output[0], dim=0)\n","\n","    # 結果を表示する\n","    top5_probs, top5_idxs = torch.topk(predicted, 3)\n","\n","    for i in range(3):\n","        print(f'{classes[top5_idxs[i]]}: {top5_probs[i]:.2%}')\n","    \n","    os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n","    input_tensor = input_tensor.to('cpu')\n","\n","    # 結果表示\n","    image = transforms.ToPILImage()(input_tensor[0])\n","\n","    _, ax = plt.subplots(figsize=(6, 6))\n","    ax.imshow(image)\n","    ax.axis('off')\n","    plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP+rp77g4Vm8qYB7FgkRnX/","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":0}
